{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS48YVETZsHM",
        "colab_type": "text"
      },
      "source": [
        "Author : Swati Sajee Kumar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgTpW1dpY8Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHV2DztibES",
        "colab_type": "text"
      },
      "source": [
        "Read data file using pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmcSvLn7Z_4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data= pd.read_csv('wdbc.dataset',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl0RQD94aW59",
        "colab_type": "text"
      },
      "source": [
        "Drop the column containg the Patient IDs which is the first column in the data file.\n",
        "Also Map the string M and B to 1 and 0 respectiviely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNsQ9YqgaX6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(0,1)\n",
        "data[1] = data[1].map({'M':1,'B':0})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLlMo9QObVid",
        "colab_type": "text"
      },
      "source": [
        "Normalize the data excluding the first column which says M or B (mapped to 0 or 1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rymJ1hTObWHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp1 = data[1]\n",
        "temp2= data.iloc[:,1:31]\n",
        "data_norm= ((temp2-temp2.min())/(temp2.max()-temp2.min()))*20\n",
        "data_norm[1]=data[1]\n",
        "c= list(data_norm.columns)\n",
        "c= c[-1:]+c[:-1]\n",
        "data_norm = data_norm[c]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuxVfNdGjzL6",
        "colab_type": "text"
      },
      "source": [
        "Now split the data into three sets: train, test and validaton\n",
        "Initially divide the data into two set 80% train and 20% test. Later divide this 20% to 10% and 10% for test and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scDL3_43jzmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test=train_test_split(data_norm,test_size=0.2,random_state=3)\n",
        "test,valid=train_test_split(test,test_size=0.5,random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-z3vNLBlRKV",
        "colab_type": "text"
      },
      "source": [
        "Convert the data into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjrytvxqlRfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.asarray(train.loc[:,2:31])\n",
        "y_train = np.asarray(train.loc[:,1])\n",
        "\n",
        "x_test = np.asarray(test.loc[:,2:31])\n",
        "y_test = np.asarray(test.loc[:,1])\n",
        "\n",
        "x_valid = np.asarray(valid.loc[:,2:31])\n",
        "y_valid = np.asarray(valid.loc[:,1])\n",
        "\n",
        "#print(len(y_test))\n",
        "#print(len(y_train))\n",
        "#print(len(y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNDYdhnWmD5D",
        "colab_type": "text"
      },
      "source": [
        "Use LogReg (Logistic Regression) function to train our model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzL7VWkmmESC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def LogReg(x_train,y_train,iterate,lr):\n",
        "\n",
        "\n",
        "  #intialize the weights and bias to zero\n",
        "  \n",
        "  #instead of taking transpose of weights later we have resized so as the number of rows in theta is equal to the number of columns in x_train\n",
        "  theta1 = np.zeros(x_train.shape[1])   \n",
        "  theta0 =0 \n",
        "  \n",
        "  loss_plot=[]\n",
        "\n",
        "  # get the number of samples\n",
        "  m = y_train.size\n",
        "  \n",
        "  # GRADIENT DESCENT Algorithm to repeatedly update the theta value\n",
        "\n",
        "  for i in range(iterate):\n",
        "\n",
        "    z= np.dot(x_train,theta1)                       #dot product of theta1 and x_train to calculate the sigmoid function\n",
        "    \n",
        "    sigma = 1/(1+np.exp(-z))                        # getting the sigmoid function \n",
        "    # print(sigma)\n",
        "    \n",
        "    grad_des = np.dot(x_train.T,(sigma-y_train))/m  # Get the partial differentiation of the cost function for all the m samples with respect to theta \n",
        "    \n",
        "    theta1-=lr*grad_des                             #updating the theta value \n",
        "    \n",
        "    if( i % 2000 ==0):                             \n",
        "      \n",
        "      z= np.dot(x_train,theta1)    \n",
        "      sigma = 1/(1+np.exp(-z))\n",
        "      loss = (-y_train * np.log(sigma) - (1 - y_train) * np.log(1 -sigma)).mean()    #Calculating the loss for every 2000 iterations so as to plot a graph for 5 set of values\n",
        "      loss_plot.append(loss)\n",
        "     \n",
        "      \n",
        "  dict = {\"theta0\":theta0,\"theta1\":theta1,\"loss\":loss,\"loss_plot\":loss_plot}      #store the values of updated weightsa nd loss function into dictonary\n",
        "  \n",
        "  return dict\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx5y8XgN1LIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict function to predict the y value for every data input x\n",
        "def predict (data, theta0,theta1):\n",
        "\n",
        "  m = data.shape[1]   #number of samples\n",
        "  \n",
        "  y_predict = np.zeros((1,m))  #initialising y_predict to zeros\n",
        "  \n",
        "  theta1 = theta1.reshape(data.shape[0],1) \n",
        "  #print(theta1)  \n",
        "  \n",
        "  z= np.dot(theta1.T, data)+theta0 #take the dot product to calculate z and find the sigmoid function\n",
        "  sigma = 1/(1+np.exp(-z))\n",
        "  \n",
        "  y_scatter_plot = []\n",
        " # print(y_scatter_plot)\n",
        "  patient_id = []\n",
        "    \n",
        "  for j in range (sigma.shape[1]):\n",
        "    y_scatter_plot.append(sigma[0,j])\n",
        "    patient_id.append(j)\n",
        "  \n",
        "  for i in range(sigma.shape[1]):\n",
        "    if(sigma[0,i]<0.5):\n",
        "      y_predict[0,i] = 0          #if the sigma or y is less than 0.5 , it is Benign      \n",
        "    else:\n",
        "      y_predict[0,i] = 1           #if the sigma or y is more than 0.5 ,then it is Malign \n",
        " \n",
        " #************************************** Plot -1 **************************************************************************************\n",
        "      \n",
        "#   inorder to check if our test data has been divided accurately into malign or benign with respect to line 0.5 we can plot the sigma values\n",
        "#   to plot the malign/benign vs patient_id where id is 1 to m , uncooment the below line also only call train set and with any one lr rate\n",
        "  \n",
        "#   plt.scatter(y_scatter_plot,patient_id)  \n",
        "#   plt.title ('Malign/Benign vs Patient_ID')\n",
        "#   plt.ylabel('Patients')\n",
        "#   plt.xlabel('Malign/Benign')\n",
        "#   # Customize the major grid\n",
        "#   plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "#   # Customize the minor grid\n",
        "#   plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "    \n",
        "  return y_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzdSZom16ad8",
        "colab_type": "text"
      },
      "source": [
        "Now we write a function to calculate the Precision of Training, Testing and validation data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhW3pXiElEI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perf_measure(y_actual, predicted_train):\n",
        "    TP = 0          #True Positive\n",
        "    FP = 0          #False Positive\n",
        "    TN = 0          #True Negative\n",
        "    FN = 0          #False Negative\n",
        "\n",
        "    for i in range(len(predicted_train)): \n",
        "        if y_actual[i]==predicted_train[i]==1:\n",
        "           TP += 1\n",
        "        if predicted_train[i]==1 and y_actual[i]!=predicted_train[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==predicted_train[i]==0:\n",
        "           TN += 1\n",
        "        if predicted_train[i]==0 and y_actual[i]!=predicted_train[i]:\n",
        "           FN += 1\n",
        "            \n",
        "    return (TP,FP,TN,FN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr51cyYUsCw8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVbcSn1QsDAW",
        "colab_type": "code",
        "outputId": "e3905c64-ee4c-4419-f580-08cc16f3c2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "#create empty lists to store values of loss,updated weights, training accuracy , testing accuracy for every epoch\n",
        "list_loss = [] \n",
        "weights = []\n",
        "train_acc=[]\n",
        "test_acc=[]\n",
        "valid_acc=[]\n",
        "loss_plot_list=[]\n",
        "y_predict_test_list = []\n",
        "y_predict_valid_list = []\n",
        "\n",
        "num_iterations = [2000,4000,6000,8000,10000]\n",
        "\n",
        "# The different values of Learning rates for which we test the model\n",
        "#lr_list = [0.00004,0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0008]\n",
        "\n",
        "#The most accurate result for train set was obtained using lr = 0.0008 , thus just to check train accuracy TP, FP, TN and FN use the below lr list and comment out the above lr_list\n",
        "lr_list = [0.0008]\n",
        "\n",
        "for j in range (len(lr_list)):\n",
        "  \n",
        "  #Train our model for 10,000 iterations \n",
        "  epoch = LogReg(x_train,y_train,iterate = 10000, lr=lr_list[j])    \n",
        "  loss = epoch[\"loss\"]  \n",
        "  theta1 = epoch[\"theta1\"]\n",
        "  theta0 = epoch[\"theta0\"]\n",
        "  loss_plot = epoch[\"loss_plot\"]  \n",
        "  \n",
        "  # call the prediction model with the updated weights\n",
        "  \n",
        "  y_prediction_train = predict(x_train.T, theta0,theta1) \n",
        "  y_prediction_test= predict(x_test.T, theta0,theta1) \n",
        "  y_prediction_valid= predict(x_valid.T, theta0,theta1)  \n",
        "  \n",
        "  #**************************************************** Precision calculation for Training , Testing and Validation set *********************************************\n",
        "\n",
        "  y_predic_test = [y for x in y_prediction_test for y in x]  \n",
        "  \n",
        "  TP,FP,TN,FN = perf_measure(y_test, y_predic_test)\n",
        "  \n",
        "  print('\\n For Learning Rate equals : ' + str(lr_list[j]))\n",
        "  print('\\n True Positive for testing set is: '  + str(TP) )\n",
        "  print('\\n True Negative for testing set is: ' + str(TN))\n",
        "  print('\\n False Positive for testing set is: '  + str(FP))\n",
        "  print('\\n False Negative for testing set is: '  + str(FN))\n",
        "  \n",
        "  Accuracy = (TP +TN)/(TP+TN+FP+FN)\n",
        "  Precision = (TP)/(TP+FP)\n",
        "  Recall = (TP)/(TP+FN)\n",
        "  \n",
        "  print('\\n Testing Accuracy is ' + \": {} %\".format(Accuracy*100))\n",
        "  print('\\n Testing Precision is  ' +\": {} %\".format(Precision*100))\n",
        "  print('\\n Testing Recall is  ' + \": {} %\".format(Recall*100))\n",
        "  test_acc.append(Accuracy*100)                                       #Appends the accuracy of all lr's into test_acc list\n",
        "  \n",
        "  \n",
        "  train_predic = [y for x in y_prediction_train for y in x]\n",
        "  TP,FP,TN,FN = perf_measure(y_train, train_predic)\n",
        "  train_a = (TP +TN)/(TP+TN+FP+FN)\n",
        "  print('\\n Training Accuracy is  ' + \": {} %\".format(train_a*100))\n",
        "  train_acc.append(train_a*100)                                       #Appends the accuracy of all lr's into train_acc list\n",
        "  \n",
        "  \n",
        "  valid_predic = [y for x in y_prediction_valid for y in x]\n",
        "  TP,FP,TN,FN = perf_measure(y_valid, valid_predic)\n",
        "  valid_a = (TP +TN)/(TP+TN+FP+FN)\n",
        "  print('\\n Validation Accuracy is ' + \": {} %\".format(valid_a*100))\n",
        "  valid_acc.append(valid_a*100)                                        #Appends the accuracy of all lr's into train_acc list\n",
        "  \n",
        " \n",
        "  list_loss.append(loss)\n",
        "  print(\"\\n Loss Function is \"+ \": {} %\".format(loss*100) +\"\\n ----------------------------------------------------------\" )\n",
        "  \n",
        "  weights.append(theta1)\n",
        "  loss_plot_list.append(loss_plot)\n",
        "  y_predict_test_list.append(y_prediction_test)\n",
        "  y_predict_valid_list.append(y_prediction_valid)\n",
        "  \n",
        "  j=j+1\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " For Learning Rate equals : 0.0008\n",
            "\n",
            " True Positive for testing set is: 14\n",
            "\n",
            " True Negative for testing set is: 38\n",
            "\n",
            " False Positive for testing set is: 3\n",
            "\n",
            " False Negative for testing set is: 2\n",
            "\n",
            " Testing Accuracy is : 91.22807017543859 %\n",
            "\n",
            " Testing Precision is  : 82.35294117647058 %\n",
            "\n",
            " Testing Recall is  : 87.5 %\n",
            "\n",
            " Training Accuracy is  : 95.6043956043956 %\n",
            "\n",
            " Validation Accuracy is : 98.24561403508771 %\n",
            "\n",
            " Loss Function is : 14.179916187163425 %\n",
            " ----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ficsEnAkAuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWcn5Ywk32gb",
        "colab_type": "text"
      },
      "source": [
        "Plotting graphs. Uncomment the graph section when checking for the different values of lr list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYYgqD1432-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot (1) Firstly for Learing Rate vs Testing Accuracy\n",
        "# plt.plot (lr_list, test_acc) \n",
        "# #plt.grid()\n",
        "# plt.title ('Learning Rate vs Testing Accuracy')\n",
        "# plt.ylabel('Test accuracy')\n",
        "# plt.xlabel('Learning Rate')\n",
        "# plt.xticks(lr_list, rotation='vertical')\n",
        "# plt.scatter(lr_list, test_acc)\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD3IJYEmyEzG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOFzOCAXzUtJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyePBK4SzVDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # Plot (2) Learing Rate vs Validation Accuracy\n",
        "# plt.plot (lr_list, valid_acc) \n",
        "# #plt.grid()\n",
        "# plt.title ('Learning Rate vs Validation Accuracy')\n",
        "# plt.ylabel('Validation accuracy')\n",
        "# plt.xlabel('Learning Rate')\n",
        "# plt.xticks(lr_list, rotation='vertical')\n",
        "# plt.scatter(lr_list, valid_acc)\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXaQiknov4Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot (3)  Learing Rate vs Training Accuracy\n",
        "# plt.plot (lr_list, train_acc) \n",
        "# #plt.grid()\n",
        "# plt.title ('Learning Rate vs Training Accuracy')\n",
        "# plt.ylabel('Training accuracy')\n",
        "# plt.xlabel('Learning Rate')\n",
        "# plt.xticks(lr_list, rotation='vertical')\n",
        "# plt.scatter(lr_list, train_acc)\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWqhiX7Fwfcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot 4  Learing Rate vs Error function\n",
        "# plt.plot (lr_list, list_loss) \n",
        "\n",
        "# #Title and labels\n",
        "# plt.title ('Learning Rate vs Error Function')\n",
        "# plt.ylabel('Error Function')\n",
        "# plt.xlabel('Learning Rate')\n",
        "\n",
        "# plt.xticks(lr_list, rotation='vertical')\n",
        "# plt.scatter(lr_list, list_loss)\n",
        "# plt.minorticks_on()\n",
        "\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbR2CKHoDbME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot 5   Error function vs Training Accuracy for different values of lr\n",
        "# plt.scatter(list_loss, train_acc)\n",
        "# plt.title ('Error Function vs Training Accuracy (for different values of lr)')\n",
        "# plt.ylabel('Training Accuracy')\n",
        "# plt.xlabel('Error Function')\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zU0CcsZJVg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot 6   Error function vs Testing Accuracy for different values of lr\n",
        "# plt.scatter(list_loss, test_acc)\n",
        "# plt.title ('Error Function vs Testing Accuracy (for different values of lr)')\n",
        "# plt.ylabel('Testing Accuracy')\n",
        "# plt.xlabel('Error Function')\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNZnjfY6JiFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot 7   Error function vs Validation Accuracy for different values of lr\n",
        "# plt.scatter(list_loss, train_acc)\n",
        "# plt.title ('Error Function vs Validation Accuracy (for different values of lr)')\n",
        "# plt.ylabel('Validation Accuracy')\n",
        "# plt.xlabel('Error Function')\n",
        "# plt.minorticks_on()\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxd6MnrhJs_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot 9   Number of iterations vs Cost for every epoch\n",
        "# plt.plot(num_iterations,loss_plot_list[0],'r', label ='lr = 0.00004')\n",
        "# plt.plot(num_iterations,loss_plot_list[1],'black',label ='lr = 0.0002')\n",
        "# plt.plot(num_iterations,loss_plot_list[2],'g',label ='lr = 0.0003')\n",
        "# plt.plot(num_iterations,loss_plot_list[3],'y',label ='lr = 0.0004')\n",
        "# plt.plot(num_iterations,loss_plot_list[4],'grey',label ='lr = 0.0006')\n",
        "# plt.plot(num_iterations,loss_plot_list[5],'b--',label ='lr = 0.0008')\n",
        "\n",
        "# plt.legend(loc='upper right');\n",
        "# plt.title (' No. of iterations vs Cost')\n",
        "# plt.ylabel('Cost')\n",
        "# plt.xlabel('#iterations')\n",
        "\n",
        "# plt.minorticks_on()\n",
        "\n",
        "# # Customize the major grid\n",
        "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
        "# # Customize the minor grid\n",
        "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdOVuhu2qTUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}